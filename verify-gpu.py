#!/usr/bin/env python3
"""
Quick GPU Verification Script
Verifica rapidamente se o worker est√° usando GPU corretamente
"""

import subprocess
import sys

def run_cmd(cmd):
    """Executa comando e retorna output"""
    try:
        result = subprocess.run(
            cmd,
            shell=True,
            capture_output=True,
            text=True,
            check=True
        )
        return result.stdout.strip()
    except subprocess.CalledProcessError as e:
        return f"ERRO: {e.stderr}"

def main():
    print("\n" + "="*60)
    print("üîç VERIFICA√á√ÉO R√ÅPIDA - GPU WORKER")
    print("="*60)
    
    # 1. Verifica se worker est√° rodando
    print("\n1Ô∏è‚É£  Verificando se worker est√° rodando...")
    status = run_cmd("docker ps --filter name=careca-worker --format '{{.Status}}'")
    if "Up" in status and "healthy" in status:
        print(f"   ‚úÖ Worker rodando: {status}")
    else:
        print(f"   ‚ùå Worker n√£o est√° healthy: {status}")
        return 1
    
    # 2. Verifica GPU acess√≠vel
    print("\n2Ô∏è‚É£  Verificando acesso √† GPU...")
    gpu_info = run_cmd("docker exec careca-worker nvidia-smi --query-gpu=name,memory.used --format=csv,noheader")
    if "RTX 4060" in gpu_info:
        print(f"   ‚úÖ GPU acess√≠vel: {gpu_info}")
    else:
        print(f"   ‚ùå GPU n√£o detectada: {gpu_info}")
        return 1
    
    # 3. Verifica PyTorch CUDA
    print("\n3Ô∏è‚É£  Verificando PyTorch + CUDA...")
    cuda_check = run_cmd('docker exec careca-worker python -c "import torch; print(torch.cuda.is_available())"')
    if "True" in cuda_check:
        print(f"   ‚úÖ PyTorch detecta CUDA: {cuda_check}")
    else:
        print(f"   ‚ùå PyTorch n√£o detecta CUDA: {cuda_check}")
        return 1
    
    # 4. Verifica vari√°veis de ambiente
    print("\n4Ô∏è‚É£  Verificando configura√ß√£o...")
    device = run_cmd('docker exec careca-worker sh -c "echo $DEVICE"')
    compute = run_cmd('docker exec careca-worker sh -c "echo $COMPUTE_TYPE"')
    model = run_cmd('docker exec careca-worker sh -c "echo $WHISPER_MODEL"')
    
    print(f"   DEVICE: {device}")
    print(f"   COMPUTE_TYPE: {compute}")
    print(f"   WHISPER_MODEL: {model}")
    
    if device == "cuda" and compute == "int8_float16" and model == "small":
        print("   ‚úÖ Configura√ß√£o otimizada para GPU!")
    else:
        print("   ‚ö†Ô∏è  Configura√ß√£o pode n√£o estar otimizada")
    
    # 5. Verifica logs recentes
    print("\n5Ô∏è‚É£  Verificando logs do worker...")
    logs = run_cmd("docker logs careca-worker --tail=3 2>&1")
    if "Listening on transcription_tasks" in logs:
        print("   ‚úÖ Worker escutando na fila")
    else:
        print(f"   ‚ö†Ô∏è  Logs: {logs[:100]}...")
    
    # Resumo final
    print("\n" + "="*60)
    print("‚úÖ VERIFICA√á√ÉO COMPLETA - TUDO OK!")
    print("="*60)
    print("\nüìù Pr√≥ximos passos:")
    print("   1. Acesse: http://localhost:8000")
    print("   2. Fa√ßa upload de um √°udio")
    print("   3. Monitore GPU: watch -n 1 nvidia-smi")
    print("   4. Monitore logs: docker-compose logs -f worker")
    print("\nüí° Esperado:")
    print("   - GPU Usage aumenta durante transcri√ß√£o")
    print("   - Velocidade: 10-20x tempo real")
    print("   - VRAM: 2-4GB durante processamento")
    print("="*60 + "\n")
    
    return 0

if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\n‚ùå Verifica√ß√£o cancelada pelo usu√°rio")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå Erro: {e}")
        sys.exit(1)
