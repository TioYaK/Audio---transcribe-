# ============================================
# GPU Override Configuration
# ============================================
# Use this file to enable GPU support for the worker
#
# Usage:
#   docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up -d worker
#
# This configuration:
# 1. Enables NVIDIA GPU support
# 2. Temporarily allows internet access for model download
# 3. Sets GPU-optimized environment variables
# ============================================

services:
  worker:
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 16G # Aumentado de 8G para 16G (evita OOM kills)
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]

    environment:
      # GPU Configuration
      - DEVICE=cuda
      - COMPUTE_TYPE=int8_float16 # Otimizado para GPU (melhor que int8)
      - WHISPER_MODEL=small # Melhor para 8GB VRAM (medium usa ~5GB)

      # Worker Configuration
      - WORKER_MAX_MEMORY_MB=14000
      - WORKER_MAX_JOBS=100
      - RQ_WORKER_COUNT=2

      # NVIDIA Environment
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

    # Temporarily connect to frontend network for internet access
    # This allows downloading the Whisper model from HuggingFace
    networks:
      - backend
      - database
      - frontend # Added for model download
