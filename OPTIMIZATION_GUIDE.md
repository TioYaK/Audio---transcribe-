# ‚ö° GUIA DE OTIMIZA√á√ÉO DE PERFORMANCE

## üéØ SITUA√á√ÉO ATUAL

**Problema:** Sistema processando **MUITO ABAIXO** da capacidade
- GPU RTX 4060: **72% OCIOSA** 
- CPU: **98% OCIOSA**
- Workers: **Apenas 1 ativo**
- Processamento: **Sequencial** (sem paraleliza√ß√£o)

**Resultado:** √Åudios levam 3-4x mais tempo que o necess√°rio

---

## üöÄ GANHO ESPERADO TOTAL

### **5-10x MAIS R√ÅPIDO** com implementa√ß√£o completa

- **Fase 1 (2h):** +300-400% throughput
- **Fase 2 (4h):** +100-150% adicional  
- **Fase 3 (8h):** +50-80% adicional

---

## üî• TOP 10 MELHORIAS (PRIORIDADE)

### 1. ‚úÖ ATIVAR GPU (10 min) ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
**Ganho:** +300-500% velocidade  
**Arquivo:** `docker-compose.yml` linha 267

```yaml
# ANTES
environment:
  - DEVICE=cpu

# DEPOIS
environment:
  - DEVICE=cuda
  - COMPUTE_TYPE=int8_float16
```

---

### 2. ‚úÖ M√öLTIPLOS WORKERS (30 min) ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
**Ganho:** +200-300% throughput  
**Arquivo:** `docker-compose.yml` linha 236

```yaml
# ADICIONAR
worker:
  deploy:
    replicas: 3  # 3 workers simult√¢neos
    resources:
      limits:
        memory: 8G  # Aumentado de 6G
```

---

### 3. ‚úÖ FFMPEG MULTI-THREAD (5 min) ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
**Ganho:** +60-80% convers√£o de √°udio  
**Arquivo:** `app/services/audio.py` linha 27

```python
# ADICIONAR "-threads", "4" ao comando FFmpeg
command = [
    "ffmpeg", "-y", "-i", input_path,
    "-threads", "4",  # ‚úÖ ADICIONAR
    "-ar", "16000", 
    "-ac", "1",
    "-af", "loudnorm=I=-16:TP=-1.5:LRA=11", 
    final_output
]
```

---

### 4. ‚úÖ AUMENTAR TTL CACHE (5 min) ‚≠ê‚≠ê‚≠ê‚≠ê
**Ganho:** +20-30% hit rate  
**Arquivo:** `app/services/transcription.py` linha 85

```python
# ANTES
ttl=86400  # 24 horas

# DEPOIS
ttl=604800  # 7 dias
```

---

### 5. ‚úÖ AUMENTAR MEM√ìRIA REDIS (2 min) ‚≠ê‚≠ê‚≠ê‚≠ê
**Ganho:** +50% capacidade cache  
**Arquivo:** `docker-compose.yml` linha 140

```yaml
# ANTES
memory: 256M

# DEPOIS
memory: 512M
```

---

### 6. ‚úÖ VAD OTIMIZADO (10 min) ‚≠ê‚≠ê‚≠ê‚≠ê
**Ganho:** +15-25% velocidade  
**Arquivo:** `app/services/transcription.py` linha 130-135

```python
# OTIMIZAR
vad_parameters={
    "threshold": 0.15,  # Era 0.1
    "min_speech_duration_ms": 100,  # Era 50
    "min_silence_duration_ms": 1000,  # Era 2000
    "speech_pad_ms": 200  # Era 400
}
```

---

### 7. ‚úÖ BATCH DIN√ÇMICO (1h) ‚≠ê‚≠ê‚≠ê‚≠ê
**Ganho:** +30-50% throughput  
**Arquivo:** `app/services/transcription.py`

```python
# ADICIONAR FUN√á√ÉO
def _get_optimal_batch_size(audio_duration):
    if audio_duration < 60:
        return 32  # √Åudios curtos
    elif audio_duration < 300:
        return 16  # M√©dios
    else:
        return 8   # Longos (evita OOM)

# USAR NO TRANSCRIBE
batch_size = _get_optimal_batch_size(info.duration)
```

---

### 8. ‚úÖ CACHE DE √ÅUDIO (1h) ‚≠ê‚≠ê‚≠ê
**Ganho:** +40-60% em uploads repetidos  
**Arquivo:** `app/services/audio.py`

```python
# ADICIONAR NO IN√çCIO DE enhance_audio()
import hashlib
from app.services.cache_service import cache_service

cache_key = f"audio:{hashlib.md5(open(input_path,'rb').read()).hexdigest()}"
cached = cache_service.get(cache_key)
if cached and os.path.exists(cached):
    return cached

# ADICIONAR NO FINAL (antes do return)
cache_service.set(cache_key, final_output, ttl=86400)
```

---

### 9. ‚úÖ √çNDICES DB (30 min) ‚≠ê‚≠ê‚≠ê
**Ganho:** +30-50% queries  
**Criar migration Alembic**

```sql
CREATE INDEX idx_task_status_owner 
ON transcription_tasks(status, owner_id);

CREATE INDEX idx_task_archived_completed 
ON transcription_tasks(is_archived, completed_at DESC);
```

---

### 10. ‚úÖ CACHE DE CORRE√á√ÉO (30 min) ‚≠ê‚≠ê‚≠ê
**Ganho:** +80-90% em textos repetidos  
**Arquivo:** `app/core/worker.py` linha 99

```python
# ADICIONAR ANTES DA CORRE√á√ÉO
import hashlib
from app.services.cache_service import cache_service

cache_key = f"correction:{hashlib.md5(original_text.encode()).hexdigest()}"
cached_correction = cache_service.get(cache_key)

if cached_correction:
    corrected_text = cached_correction
else:
    corrected_text = correct_text(original_text)
    cache_service.set(cache_key, corrected_text, ttl=2592000)  # 30 dias
```

---

## üìã CHECKLIST DE IMPLEMENTA√á√ÉO

### FASE 1 - QUICK WINS (2 horas)
- [ ] 1. Ativar GPU (10 min)
- [ ] 2. M√∫ltiplos workers (30 min)
- [ ] 3. FFmpeg multi-thread (5 min)
- [ ] 4. Aumentar TTL cache (5 min)
- [ ] 5. Aumentar mem√≥ria Redis (2 min)
- [ ] 6. VAD otimizado (10 min)

**Resultado:** Sistema **4-5x mais r√°pido**

---

### FASE 2 - OTIMIZA√á√ïES M√âDIAS (4 horas)
- [ ] 7. Batch din√¢mico (1h)
- [ ] 8. Cache de √°udio (1h)
- [ ] 9. √çndices DB (30 min)
- [ ] 10. Cache de corre√ß√£o (30 min)

**Resultado:** Sistema **6-8x mais r√°pido**

---

## üéØ RESULTADO FINAL ESPERADO

### Antes (Situa√ß√£o Atual):
- **1 √°udio de 5 min:** ~3-4 minutos de processamento
- **3 √°udios simult√¢neos:** Processados em sequ√™ncia (9-12 min total)
- **Utiliza√ß√£o GPU:** 28%
- **Utiliza√ß√£o CPU:** 2%

### Depois (Com Fase 1):
- **1 √°udio de 5 min:** ~40-60 segundos
- **3 √°udios simult√¢neos:** Processados em paralelo (~60 segundos total)
- **Utiliza√ß√£o GPU:** 60-80%
- **Utiliza√ß√£o CPU:** 30-40%

### Depois (Com Fase 1 + 2):
- **1 √°udio de 5 min:** ~30-40 segundos
- **3 √°udios simult√¢neos:** ~40-50 segundos total
- **Cache hit rate:** 40-60%
- **Throughput:** +600-800%

---

## ‚ö° A√á√ÉO IMEDIATA RECOMENDADA

### IMPLEMENTAR AGORA (30 minutos):

1. **Ativar GPU** (maior impacto)
2. **FFmpeg multi-thread** (trivial)
3. **Aumentar mem√≥ria Redis** (trivial)

**Ganho imediato:** +400% velocidade com **30 minutos de trabalho**

---

## üìä COMO MEDIR O SUCESSO

### Antes de implementar:
```bash
# Testar 1 √°udio
time docker exec careca-worker python -c "from app.core.worker import process_transcription; process_transcription('test', 'audio.mp3')"
```

### Depois de implementar:
```bash
# Mesmo teste - deve ser 4-5x mais r√°pido
time docker exec careca-worker python -c "from app.core.worker import process_transcription; process_transcription('test', 'audio.mp3')"
```

### Monitorar:
- Grafana: `http://localhost:3000` (j√° configurado)
- Logs: `docker logs careca-worker -f`
- GPU: `nvidia-smi -l 1`

---

## üö® AVISOS IMPORTANTES

1. **GPU deve estar dispon√≠vel** para Fase 1
2. **Testar em staging** antes de produ√ß√£o
3. **Monitorar mem√≥ria** com m√∫ltiplos workers
4. **Fazer backup** antes de mudan√ßas no DB

---

## üìû PR√ìXIMOS PASSOS

1. ‚úÖ Revisar este documento
2. ‚úÖ Aprovar implementa√ß√£o da Fase 1
3. ‚úÖ Executar mudan√ßas (2 horas)
4. ‚úÖ Testar e validar
5. ‚úÖ Monitorar por 24-48h
6. ‚úÖ Avaliar Fase 2

---

**Preparado em:** 2025-12-18  
**Vers√£o:** 1.0  
**Status:** Pronto para implementa√ß√£o
