"""
Worker RQ Customizado com Gerenciamento de Mem√≥ria
Previne OOM monitorando uso de mem√≥ria durante execu√ß√£o de jobs
"""
import psutil
import signal
import sys
import os
from rq import Worker
from rq.job import Job
from typing import Optional
import logging

logger = logging.getLogger(__name__)


class CustomWorker(Worker):
    """
    Worker RQ Customizado com gerenciamento de mem√≥ria aprimorado e shutdown gracioso
    """
    
    def __init__(self, *args, max_memory_mb: int = 3500, max_jobs: int = 100, **kwargs):
        """
        Inicializa o worker customizado
        
        Args:
            max_memory_mb: Mem√≥ria m√°xima em MB antes de rejeitar jobs (padr√£o: 3.5GB)
            max_jobs: M√°ximo de jobs antes de reiniciar worker (padr√£o: 100)
        """
        # Armazenar max_jobs antes de passar para pai
        self.max_jobs = max_jobs
        super().__init__(*args, **kwargs)
        self.max_memory_mb = max_memory_mb
        self.jobs_processed = 0
        
        # Configurar shutdown gracioso
        signal.signal(signal.SIGTERM, self._handle_shutdown)
        signal.signal(signal.SIGINT, self._handle_shutdown)
    
    def _handle_shutdown(self, signum, frame):
        """Trata shutdown gracioso em SIGTERM/SIGINT"""
        logger.info(f"üõë Sinal {signum} recebido, encerrando graciosamente...")
        self.request_stop()
    
    def execute_job(self, job: Job, queue) -> bool:
        """
        Executa job com monitoramento de mem√≥ria
        
        Args:
            job: Inst√¢ncia do Job RQ
            queue: Inst√¢ncia da fila
            
        Returns:
            bool: True se job executou com sucesso
        """
        try:
            # Verificar mem√≥ria antes da execu√ß√£o
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            
            if memory_mb > self.max_memory_mb:
                error_msg = f"Limite de mem√≥ria excedido: {memory_mb:.2f}MB > {self.max_memory_mb}MB"
                logger.error(f"‚ùå {error_msg}")
                
                job.set_status('failed')
                job.meta['error'] = error_msg
                job.meta['memory_mb'] = memory_mb
                job.save()
                
                return False
            
            # Log in√≠cio do job
            logger.info(
                f"‚ñ∂Ô∏è  Iniciando job {job.id} | "
                f"Mem√≥ria: {memory_mb:.2f}MB | "
                f"Jobs processados: {self.jobs_processed}/{self.max_jobs}"
            )
            
            # Executar job
            result = super().execute_job(job, queue)
            
            # Atualizar contador
            self.jobs_processed += 1
            
            # Log conclus√£o
            memory_after = process.memory_info().rss / 1024 / 1024
            logger.info(
                f"‚úÖ Job {job.id} conclu√≠do | "
                f"Mem√≥ria: {memory_after:.2f}MB | "
                f"Delta: {memory_after - memory_mb:+.2f}MB"
            )
            
            # Verificar se atingiu max jobs
            if self.jobs_processed >= self.max_jobs:
                logger.warning(
                    f"‚ö†Ô∏è  M√°ximo de jobs atingido ({self.max_jobs}), "
                    "worker ser√° reiniciado ap√≥s job atual"
                )
                # Usar request_stop com argumentos dummy para evitar erro
                self.request_stop(None, None)
            
            return result
            
        except Exception as e:
            logger.exception(f"‚ùå Erro ao executar job {job.id}: {e}")
            job.set_status('failed')
            job.meta['error'] = str(e)
            job.save()
            return False
    
    def work(self, *args, **kwargs):
        """Sobrescreve m√©todo work para adicionar log de inicializa√ß√£o"""
        logger.info(
            f"üöÄ Worker iniciado | "
            f"Mem√≥ria M√°x: {self.max_memory_mb}MB | "
            f"Jobs M√°x: {self.max_jobs}"
        )
        return super().work(*args, **kwargs)


def _get_redis_url() -> str:
    """
    Obt√©m URL do Redis de forma segura.
    Tenta primeiro via m√≥dulo de secrets, depois vari√°veis de ambiente.
    """
    # 1. Tentar via m√≥dulo de secrets
    try:
        from app.core.secrets import get_redis_url
        return get_redis_url()
    except Exception as e:
        logger.warning(f"Falha ao carregar URL do Redis via secrets: {e}")
    
    # 2. Fallback: vari√°veis de ambiente
    redis_host = os.getenv("REDIS_HOST", "redis")
    redis_port = os.getenv("REDIS_PORT", "6379")
    redis_db = os.getenv("REDIS_DB", "0")
    
    # 3. Senha: priorizar arquivo de secret, depois env var
    redis_password = ""
    secret_path = os.getenv("REDIS_PASSWORD_FILE", "/run/secrets/redis_password")
    
    if os.path.exists(secret_path):
        try:
            with open(secret_path, "r") as f:
                redis_password = f.read().strip()
        except Exception as e:
            logger.warning(f"N√£o foi poss√≠vel ler secret do Redis: {e}")
    
    if not redis_password:
        redis_password = os.getenv("REDIS_PASSWORD", "")
    
    return f"redis://:{redis_password}@{redis_host}:{redis_port}/{redis_db}"


def main():
    """Ponto de entrada principal para worker customizado"""
    from redis import Redis
    
    redis_url = _get_redis_url()
    redis_conn = Redis.from_url(redis_url)
    
    # Criar worker
    worker = CustomWorker(
        ['transcription_tasks'],
        connection=redis_conn,
        max_memory_mb=int(os.getenv('WORKER_MAX_MEMORY_MB', '3500')),
        max_jobs=int(os.getenv('WORKER_MAX_JOBS', '100'))
    )
    
    # Iniciar worker
    worker.work(with_scheduler=True, burst=False)


if __name__ == '__main__':
    main()
