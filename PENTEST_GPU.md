# üîç PEN-TEST E VERIFICA√á√ÉO COMPLETA - GPU WORKER

## ‚úÖ VERIFICA√á√ïES REALIZADAS

### 1. Sistema Base
- [x] **Python 3.11.9** instalado
- [x] **Docker 29.1.2** instalado e funcionando
- [x] **GPU RTX 4060** detectada
- [x] **Driver NVIDIA 591.44** (atualizado - Dezembro 2025)
- [x] **CUDA 13.1** dispon√≠vel

### 2. Docker + GPU
- [x] **NVIDIA Container Toolkit** funcionando
- [x] **Docker consegue acessar GPU** (testado com nvidia/cuda:12.1.0)
- [x] **nvidia-smi** funciona dentro de containers

### 3. Configura√ß√£o do Projeto

#### ‚úÖ Arquivos Verificados:
- `docker-compose.yml` - Configura√ß√£o base (worker usa CPU por padr√£o)
- `docker-compose.gpu.yml` - Override para GPU
- `Dockerfile` - Otimizado para GPU com LD_LIBRARY_PATH correto
- `requirements.txt` - Todas as depend√™ncias necess√°rias

#### ‚ö†Ô∏è CONFIGURA√á√ÉO ATUAL DO WORKER:

**docker-compose.yml (linhas 267-269):**
```yaml
- DEVICE=cpu # For√ßar CPU (CUDA n√£o dispon√≠vel)
- WHISPER_MODEL=${WHISPER_MODEL:-medium}
- COMPUTE_TYPE=int8 # CPU suporta apenas int8
```

**docker-compose.gpu.yml (linhas 30-32):**
```yaml
- DEVICE=cuda
- COMPUTE_TYPE=int8
- WHISPER_MODEL=medium
```

## üéØ PROBLEMAS IDENTIFICADOS

### 1. ‚ùå COMPUTE_TYPE INCORRETO PARA GPU
**Problema:** `COMPUTE_TYPE=int8` √© otimizado para CPU, n√£o GPU!

**Para RTX 4060, voc√™ deve usar:**
- `int8_float16` - Melhor performance/qualidade
- `float16` - M√°xima qualidade
- `int8` - Apenas para CPU

### 2. ‚ö†Ô∏è MODELO MEDIUM PODE SER PESADO
**RTX 4060 tem 8GB VRAM:**
- `tiny` - ~1GB VRAM, muito r√°pido
- `base` - ~1GB VRAM, r√°pido
- `small` - ~2GB VRAM, bom equil√≠brio
- `medium` - ~5GB VRAM, qualidade alta
- `large-v2` - ~10GB VRAM, **N√ÉO RECOMENDADO para 4060**

## üîß CORRE√á√ïES NECESS√ÅRIAS

### 1. Atualizar docker-compose.gpu.yml

**ANTES:**
```yaml
environment:
  - DEVICE=cuda
  - COMPUTE_TYPE=int8
  - WHISPER_MODEL=medium
```

**DEPOIS:**
```yaml
environment:
  - DEVICE=cuda
  - COMPUTE_TYPE=int8_float16  # ‚úÖ OTIMIZADO PARA GPU
  - WHISPER_MODEL=small        # ‚úÖ MELHOR PARA 8GB VRAM
```

### 2. Verificar LD_LIBRARY_PATH no Dockerfile

**Linha 63 do Dockerfile est√° correta:**
```dockerfile
ENV LD_LIBRARY_PATH="/home/appuser/.local/lib/python3.11/site-packages/nvidia/cublas/lib:/home/appuser/.local/lib/python3.11/site-packages/nvidia/cudnn/lib:$LD_LIBRARY_PATH"
```

## üìã CHECKLIST DE DEPLOY

### Pr√©-Deploy:
- [ ] Parar todos os containers: `docker-compose down`
- [ ] Limpar cache Docker: `docker system prune -a --volumes -f`
- [ ] Verificar secrets existem em `./secrets/`
- [ ] Verificar arquivo `.env` existe

### Build:
- [ ] Build das imagens: `docker-compose build --no-cache`
- [ ] Verificar imagem criada: `docker images | grep careca`

### Deploy Sequencial:
1. [ ] Iniciar database: `docker-compose up -d db`
2. [ ] Aguardar healthy: `docker-compose ps db`
3. [ ] Iniciar redis: `docker-compose up -d redis`
4. [ ] Aguardar healthy: `docker-compose ps redis`
5. [ ] Iniciar app: `docker-compose up -d app`
6. [ ] Aguardar healthy: `docker-compose ps app`
7. [ ] **Iniciar worker com GPU**: `docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up -d worker`
8. [ ] Iniciar nginx: `docker-compose up -d web`

### P√≥s-Deploy - Verifica√ß√µes:
- [ ] Todos containers healthy: `docker-compose ps`
- [ ] Worker usando GPU: `docker exec careca-worker nvidia-smi`
- [ ] Logs do worker sem erros: `docker-compose logs worker`
- [ ] Teste de transcri√ß√£o funciona

## üß™ TESTES DE VALIDA√á√ÉO

### Teste 1: GPU Acess√≠vel no Container
```bash
docker exec careca-worker nvidia-smi
```
**Esperado:** Deve mostrar RTX 4060

### Teste 2: PyTorch Detecta CUDA
```bash
docker exec careca-worker python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```
**Esperado:** `CUDA: True`

### Teste 3: Faster-Whisper com GPU
```bash
docker exec careca-worker python gpu-test.py
```
**Esperado:** Todos os testes passam

### Teste 4: Transcri√ß√£o Real
1. Acesse http://localhost:8000
2. Fa√ßa upload de um arquivo de √°udio
3. Monitore logs: `docker-compose logs -f worker`
4. Verifique uso da GPU: `watch -n 1 nvidia-smi`

**Esperado:** 
- GPU Usage aumenta durante transcri√ß√£o
- Logs mostram "Using device: cuda"
- Transcri√ß√£o completa com sucesso

## üìä M√âTRICAS ESPERADAS

### Performance com GPU (RTX 4060):
- **Modelo small + int8_float16:**
  - Velocidade: ~10-20x tempo real
  - VRAM: ~2-3GB
  - Qualidade: Excelente para portugu√™s

- **Modelo medium + int8_float16:**
  - Velocidade: ~5-10x tempo real
  - VRAM: ~4-5GB
  - Qualidade: M√°xima para portugu√™s

### Compara√ß√£o CPU vs GPU:
- **CPU (current):** ~0.5-1x tempo real (MUITO LENTO)
- **GPU (small):** ~10-20x tempo real (R√ÅPIDO)
- **GPU (medium):** ~5-10x tempo real (R√ÅPIDO + QUALIDADE)

## üö® TROUBLESHOOTING

### Erro: "CUDA driver version is insufficient"
**Solu√ß√£o:** Driver est√° OK (591.44), verificar CUDA runtime no container

### Erro: "CUDA out of memory"
**Solu√ß√£o:** Usar modelo menor (small ao inv√©s de medium)

### Erro: "Could not load library libcudnn"
**Solu√ß√£o:** Verificar LD_LIBRARY_PATH no Dockerfile (linha 63)

### Worker n√£o usa GPU
**Verificar:**
1. `docker-compose.gpu.yml` est√° sendo usado no comando up
2. `DEVICE=cuda` est√° setado
3. `deploy.resources.reservations.devices` est√° configurado

## üéØ COMANDOS √öTEIS

### Monitorar GPU em tempo real:
```bash
watch -n 1 nvidia-smi
```

### Ver logs do worker:
```bash
docker-compose logs -f worker
```

### Reiniciar apenas worker:
```bash
docker-compose -f docker-compose.yml -f docker-compose.gpu.yml restart worker
```

### Entrar no container do worker:
```bash
docker exec -it careca-worker bash
```

### Verificar vari√°veis de ambiente:
```bash
docker exec careca-worker env | grep -E "(DEVICE|COMPUTE_TYPE|WHISPER_MODEL)"
```

## ‚úÖ CONCLUS√ÉO

**Status Atual:**
- ‚úÖ Hardware: GPU RTX 4060 funcionando perfeitamente
- ‚úÖ Software: Docker + NVIDIA Container Toolkit OK
- ‚ö†Ô∏è Configura√ß√£o: Precisa ajustar COMPUTE_TYPE para GPU

**Pr√≥ximos Passos:**
1. Corrigir `docker-compose.gpu.yml` (COMPUTE_TYPE)
2. Rebuild das imagens
3. Deploy sequencial
4. Testes de valida√ß√£o
5. Monitorar performance

**Resultado Esperado:**
üöÄ Worker processando transcri√ß√µes na GPU com velocidade 10-20x mais r√°pida que CPU!
